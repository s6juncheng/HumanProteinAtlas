{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpa_src.config import get_data_dir, name_label_dict\n",
    "from hpa_src.data.datasets import readimg, HpaDataset, TestDataset#, train_val_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = get_data_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df = pd.read_csv(DATA + \"raw/png/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df['target_list'] = image_df['Target'].map(lambda x: [int(a) for a in x.split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "all_labels = np.array(list(itertools.chain(*image_df.target_list.values)))\n",
    "\n",
    "class_n = np.unique(all_labels, return_counts=True)[1]\n",
    "\n",
    "alpha = class_n / sum(class_n)\n",
    "\n",
    "image_df = image_df.drop(['target_list'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This code only run once\n",
    "# train_indx, val_indx = train_test_split(np.arange(image_df.shape[0]), test_size=0.2)\n",
    "\n",
    "# training = image_df.iloc[train_indx].reset_index(drop=True)\n",
    "# validation = image_df.iloc[val_indx].reset_index(drop=True)\n",
    "\n",
    "# training.to_csv(DATA+'raw/png/training.csv')\n",
    "# validation.to_csv(DATA+'raw/png/validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = torch.from_numpy(alpha).float()\n",
    "\n",
    "# alpha = alpha.cuda()\n",
    "\n",
    "# alpha.cuda(alpha.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from hpa_src.data.transforms import ToPIL\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from hpa_src.models.loss import FocalLoss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 299\n",
    "train_transform = transforms.Compose([\n",
    "    ToPIL(),\n",
    "    #transforms.Resize(input_size),\n",
    "    transforms.RandomResizedCrop(input_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1149, 0.0922, 0.0553),\n",
    "                         (0.1694, 0.1381, 0.1551))\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    ToPIL(),\n",
    "    transforms.Resize(input_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1149, 0.0922, 0.0553),\n",
    "                         (0.1694, 0.1381, 0.1551))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sampler, val_sampler = train_val_split(image_df.shape[0])\n",
    "# train_sampler, val_sampler = train_val_split(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HpaDataset(DATA + 'raw/png/training.csv', transform=train_transform)\n",
    "val_dataset = HpaDataset(DATA + 'raw/png/validation.csv', transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=16, #sampler=train_sampler,\n",
    "    num_workers=16\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=16, #sampler=val_sampler,\n",
    "    num_workers=16\n",
    ")\n",
    "\n",
    "dataloaders = {'train': train_loader, 'val': val_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrainedmodels\n",
    "pretrained = pretrainedmodels.__dict__['inceptionresnetv2'](num_classes=1000, pretrained='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class TransferedModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 pretrained,\n",
    "                 num_classes):\n",
    "        super(TransferedModel, self).__init__()\n",
    "        self.pretrained = pretrained\n",
    "        n_feature = pretrained.last_linear.in_features\n",
    "        self.classifier = nn.Sequential(\n",
    "            #nn.Linear(n_feature, n_feature),\n",
    "            #nn.BatchNorm1d(n_feature),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(n_feature, num_classes))\n",
    "        self.pretrained.last_linear = self.classifier\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pretrained(x)\n",
    "        return x\n",
    "        \n",
    "#             nn.Conv2d(n_feature, n_feature, 1),\n",
    "#             nn.ReLU(inplace=True),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/modules/i12g/anaconda/3-5.0.1/envs/hpaic/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py:24: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    }
   ],
   "source": [
    "model = TransferedModel(pretrained, 28)\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained = nn.DataParallel(pretrained, device_ids=[1])\n",
    "# pretrained = pretrained.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = BCEWithLogitsLoss()\n",
    "criterion = FocalLoss(gamma=2, logits=True)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_sizes = {'train': len(train_indx), 'val': len(val_indx)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = next(iter(dataloaders['train']))\n",
    "# pretrained(tmp[0].to_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from hpa_src.models.training import ModelTrainer\n",
    "from hpa_src.models.callbacks import TorchModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ModelTrainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.compile(optimizer_ft, criterion, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checker = TorchModelCheckpoint('../models/torch_trained', monitor='val_f1', save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First train classifier layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in trainer.model.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in trainer.model.module.classifier.parameters():\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(dataloaders['train'], dataloaders['val'], epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in trainer.model.parameters():\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(dataloaders['train'], dataloaders['val'], epochs=60, model_checker = checker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplot(121)\n",
    "fig = plt.figure(figsize=(13,5))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.plot(trainer.history.epoch, trainer.history.history['train_loss'], label='train_loss')\n",
    "ax1.plot(trainer.history.epoch, trainer.history.history['val_loss'], label='val_loss')\n",
    "ax1.legend()\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.plot(trainer.history.epoch, trainer.history.history['train_f1'], label='train_f1')\n",
    "ax2.plot(trainer.history.epoch, trainer.history.history['val_f1'], label='val_f1')\n",
    "ax2.legend()\n",
    "plt.savefig('lr0.0005_focal.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validate threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resource\n",
    "rlimit = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (2048*2, rlimit[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"../models/torch_trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset = HpaDataset(DATA + 'raw/png/train.csv', transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loader = torch.utils.data.DataLoader(\n",
    "    all_dataset, batch_size=16, #sampler=val_sampler,\n",
    "    num_workers=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    val_preds = []\n",
    "    val_true = []\n",
    "    for inputs, labels in all_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        val_preds.append(model(inputs))\n",
    "        val_true.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = torch.cat(val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_true = torch.cat(val_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpa_src.data.functional import preds2label, preds2onehot, array2str\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/modules/i12g/anaconda/3-5.0.1/envs/hpaic/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for p in np.arange(0.1,0.9,0.02):\n",
    "    #tmp = preds2onehot(val_preds, threshold=np.log(p/(1-p)))\n",
    "    scores.append(f1_score(val_true, val_preds>np.log(p/(1-p)), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAE75JREFUeJzt3X+o3Xd9x/Hnu6ndMleXYSKzN2mTjbRbZwthZ3VQmE5amylLYy2SFsGCGnR2HVTLIkqRymhnYSIsfywW0Qlb1CI1alxA2zIm68jt0h8kEo2xrvcGZiytsplp2733xzk3nntz7jnfe/M93/P9fs/zAYHzPefrPW9Oj6/zOZ/P+/M9kZlIktrlgkkXIEkqn+EuSS1kuEtSCxnuktRChrsktZDhLkktZLhLUgsZ7pLUQoa7JLXQhZN64vXr1+fmzZsn9fSS1EiPP/74jzNzw6jzJhbumzdvZnZ2dlJPL0mNFBE/LHKe0zKS1EKGuyS1kOEuSS1kuEtSCxnuktRChrsktZDhLkktZLhLUgsZ7pLUQoa7JLWQ4S5JLWS4S1ILTezCYdKCh47Mc/+h45x64QyXrFvLXTdcwc5tM5MuS2q0QiP3iNgeEccj4kRE7FnmnHdExLGIOBoR/1humWqrh47M8+EvP838C2dIYP6FM3z4y0/z0JH5Redce9/DbNnzda697+FFj0kabOTIPSLWAHuB64E54HBEHMjMY33nbAU+DFybmc9HxGvGVbCaabnR+f2HjnPmxZcXnXvmxZe5/9Bxdm6bORv+C+cshD/g6F4aosi0zDXAicw8CRAR+4EbgWN957wX2JuZzwNk5o/KLlTNNSygT71wZuD/ZuH+IuHvlI50riLTMjPAs33Hc737+l0OXB4R346IxyJie1kFqvmGBfQl69YO/N8s3D8s/ItM6UjTqki4x4D7csnxhcBW4I3ALcADEbHunD8UsTsiZiNi9vTp0yutVQ01LKDvuuEK1r5izaL7175iDXfdcAXA0PAf9qEhTbsi4T4HbOo73gicGnDOVzLzxcz8AXCcbtgvkpn7MrOTmZ0NG0b+BKAaZNii57CA3rlthntvuoqZdWsJYGbdWu696aqzUyvDwn/UlM6ouqQ2KzLnfhjYGhFbgHlgF3DrknMeojti/2xErKc7TXOyzEJVX6MWPe+64YpFj8Pi0fnObTPLzpMv3L/cYuz8gIBf+DBxMVbTbGS4Z+ZLEXE7cAhYA3wmM49GxD3AbGYe6D325og4BrwM3JWZz42zcNXHqEXPYQFdxHLhP+pDY1RdYI+92qvQJqbMPAgcXHLf3X23E7iz909Tpsj0yLDR+WqN+tAYVZcje7WZO1RVyLAR7iXr1g6dHhmnYR8ao+oqMrKXmspry2ikUS2HozpeJmVUXUW+cUhN5chdI417Tn1cRtU1amTvfLyaLLrT5dXrdDo5Ozs7kefWymzZ8/VzNjZAdwPED+57a9XllGbpnDt0R/b33nQVwLKPGfCapIh4PDM7o85zWkYjjdpF2lTDeuzdIKWmc1pGI41qOWyy5RZknY9X0xnuOmu5Oea6zqmP0yQ7gKQyGO4CRvd8j6NPvc7a/G1F08FwF2DP91JFvq3YTaM6M9wFOMc8yLBvK+5uVd3ZLSOgvR0x42I3jerOcBdQ312mdeU3HdWd4S5geM+3zuU3HdWdc+46a9o6Ys5HkW4aF1w1SYa7tAqjumlccNWkGe7SKg37pmNrqSbNcJ8iThNUxwVXTZoLqlNi1DXZVS4XXDVphvuUsC+7WraWatKclpkSThNUaxovtqZ6MdynhFc5rN6oyxcY/Bonp2WmhNME9eH6h6pguE8Jd6DWh+sfqoLTMlPEHaj14PqHquDIXaqYbZKqguEuVcz1D1XBaRmpYrZJqgqGe4vYXtccrn9o3Az3lvAqhO3iB7XOl3PuLWF7XXvYB68yGO4tYXtde/hBrTIY7i1he117+EGtMhjuLWF7XXv4Qa0yGO4t4eUF2sMPapXBbpkWsb2uHeyDVxkMd6mGvFywzpfhLjWI+xlUVKE594jYHhHHI+JEROwZ8PhtEXE6Ip7o/XtP+aVKsk1SRY0cuUfEGmAvcD0wBxyOiAOZeWzJqV/IzNvHUKOkHtskVVSRaZlrgBOZeRIgIvYDNwJLw10VcL51uvlziSqqyLTMDPBs3/Fc776l3h4RT0XEgxGxqZTqtIjb0mWbpIoqEu4x4L5ccvxVYHNmXg18E/jcwD8UsTsiZiNi9vTp0yurVM63yv0MKqzItMwc0D8S3wic6j8hM5/rO/w08DeD/lBm7gP2AXQ6naUfEBrB+VaB+xlUTJGR+2Fga0RsiYiLgF3Agf4TIuK1fYc7gO+UV6IWuC1dUlEjwz0zXwJuBw7RDe0vZubRiLgnInb0TrsjIo5GxJPAHcBt4yp4mjnfKqmoyJzM7Ein08nZ2dmJPHeT2S2jUXyPtFtEPJ6ZnVHnuUO1YZxv1TDuYNUCrwoptYgdVVpguEstYkeVFhjuUovYUaUFhrvUInZUaYELqlKLFPmhD7tppoPhLrXMqB/6sJtmOhjuNeOoSuM0rJvG91m7GO414qhK42Y3zfRwQbVG7FHWuNlNMz0M9xpxVKVxs5tmehjuNeKoSuPm9eCnh3PuNXLXDVcsmnMHR1Uqn9cnmg6Ge40U6VGWpCIM95pxVCWpDM65S1ILOXKXdJab6NrDcJcEuImubZyWkQS4ia5tDHdJgJvo2sZwlwS4ia5tDHdJgJcmaBsXVCUBbqJrG8Nd0lluomsPw71i9hGryXz/NofhXiH7iNVkvn+bxQXVCtlHrCbz/dsshnuF7CNWk/n+bRbDvUL2EavJfP82i+FeIfuI1WS+f5vFBdUK2UesJvP92yyRmRN54k6nk7OzsxN5bklqqoh4PDM7o85z5C6pNPbB14fhLqkU9sHXiwuqkkphH3y9GO6SSmEffL0Y7pJKYR98vRQK94jYHhHHI+JEROwZct7NEZERMXIlV1K72AdfLyMXVCNiDbAXuB6YAw5HxIHMPLbkvIuBO4B/H0ehkurNPvh6KdItcw1wIjNPAkTEfuBG4NiS8z4OfAL4UKkVSmoMrwdfH0WmZWaAZ/uO53r3nRUR24BNmfm1EmuTJK1SkXCPAfed3dYaERcAnwQ+OPIPReyOiNmImD19+nTxKiVJK1JkWmYO2NR3vBE41Xd8MfA64NGIAPgt4EBE7MjMRdcXyMx9wD7oXn7gPOquNXfpSZq0IuF+GNgaEVuAeWAXcOvCg5n5E2D9wnFEPAp8aGmwTwt36UmDOeip1shpmcx8CbgdOAR8B/hiZh6NiHsiYse4C2wad+lJ51oY9My/cIbkl4Oeh47MT7q01ip0bZnMPAgcXHLf3cuc+8bzL6u53KUnnWvYoMfR+3i4Q7Vk7tKTzuWgp3qGe8ncpSedy0FP9Qz3ku3cNsO9N13FzLq1BDCzbi333nSVXz011Rz0VM/ruY+Bu/Skxbw0QfUMd0mVcNBTLadlJKmFDHdJaiGnZSTVgjtYy2W4S5o4L9tRPqdlJE2cl+0on+EuaeLcwVo+w13SxLmDtXyGu6SJcwdr+VxQlTRx7mAtn+G+CrZsSeVzB2u5DPcVsmVLUhM4575CtmxJagLDfYVs2ZLUBE7LrNAl69YyPyDIbdmSxsd1rpVz5L5CtmxJ1fLHtVfHcF8hf2lJqpbrXKvjtMwq2LIlVcd1rtVx5C6p1rw0weoY7pJqzXWu1XFaRlKteWmC1THcJdWe61wr57SMJLWQ4S5JLWS4S1ILGe6S1EIuqEpqPK89cy7DfRm+WaRm8DcWBnNaZgAvVCQ1h9eeGcxwH8A3i9QcXntmMMN9AN8sUnN47ZnBDPcBfLNIzeG1ZwYz3AfwzSI1h7+xMFihbpmI2A58ClgDPJCZ9y15/H3AB4CXgf8GdmfmsZJrrYwXKpKaxWvPnCsyc/gJEWuA7wLXA3PAYeCW/vCOiFdl5k97t3cAf56Z24f93U6nk7Ozs+dZviRNl4h4PDM7o84rMi1zDXAiM09m5i+A/cCN/ScsBHvPK4HhnxiSpLEqMi0zAzzbdzwHvH7pSRHxAeBO4CLgTaVUJ0lalSLhHgPuO2dknpl7gb0RcSvwUeBd5/yhiN3AboBLL710ZZVK0ipN447zItMyc8CmvuONwKkh5+8Hdg56IDP3ZWYnMzsbNmwoXqUkrdK07jgvEu6Hga0RsSUiLgJ2AQf6T4iIrX2HbwW+V16JkrR607rjfOS0TGa+FBG3A4fotkJ+JjOPRsQ9wGxmHgBuj4jrgBeB5xkwJSNJkzCtO84L9bln5kHg4JL77u67/Zcl1yVJpbhk3VrmBwR523ecu0NVUqtN645zr+cuqdWmdce54S6p9abx8gRTG+7T2PcqaXpMZbj7s1ySFrR1oDeVC6rT2vcqabE2b3CaynCf1r5XSYu1eaA3leHuLy1JgnYP9KYy3Ke171XSYm0e6E1luPuzXJKg3QO9qeyWgense5W0WJs3OE1tuEsStHegN5XTMpLUdo7cJWmIpm5yMtwlaRlN3s3utIwkLaPJm5wMd0laRpM3ORnukrSMJm9yMtwlaRlN3uTU2gXVpq5wS6qPJm9yamW4N3mFW1K9NHWTUyunZZq8wi1JZWhluDd5hVuSytDKcG/yCrcklaGV4d7kFW5JKkMrF1SbvMItSWVoZbhDc1e4JTVLXduuWxvukjRudW67buWcuyRVoc5t14a7JK1SnduuDXdJWqU6t10b7pK0SnVuu3ZBVZJWqc5t14a7JJ2HurZdNzrc69pfKkmT1thwr3N/qSRNWmMXVOvcXypJk1Yo3CNie0Qcj4gTEbFnwON3RsSxiHgqIr4VEZeVX+pide4vlSTozjBce9/DbNnzda6972EeOjJf2XOPDPeIWAPsBf4UuBK4JSKuXHLaEaCTmVcDDwKfKLvQpercXypJC1PH8y+cIfnl1HFVAV9k5H4NcCIzT2bmL4D9wI39J2TmI5n5s97hY8DGcss8V537SyVp0lPHRRZUZ4Bn+47ngNcPOf/dwDfOp6gi6txfKkmTnjouEu4x4L4ceGLEO4EO8IZlHt8N7Aa49NJLC5a4vLr2l0rSJevWMj8gyKuaOi4yLTMHbOo73gicWnpSRFwHfATYkZk/H/SHMnNfZnYys7Nhw4bV1CtJjTDpqeMiI/fDwNaI2ALMA7uAW/tPiIhtwN8D2zPzR6VXKUkNM+mp45HhnpkvRcTtwCFgDfCZzDwaEfcAs5l5ALgf+HXgSxEB8J+ZuWOMdUtS7U1y6rjQDtXMPAgcXHLf3X23ryu5LknSeWjsDlVJ0vIMd0lqIcNdklrIcJekFjLcJamFDHdJaiHDXZJayHCXpBYy3CWphQx3SWqhyBx49d7xP3HEaeCHJf259cCPS/pbZbKulbGulalrXVDf2tpQ12WZOfKyuhML9zJFxGxmdiZdx1LWtTLWtTJ1rQvqW9s01eW0jCS1kOEuSS3UlnDfN+kClmFdK2NdK1PXuqC+tU1NXa2Yc5ckLdaWkbskqU9jwj0itkfE8Yg4ERF7Bjz+xxHxHxHxUkTcXLPa7oyIYxHxVER8KyIuq0ld74uIpyPiiYj414i4sg519Z13c0RkRFTS3VDg9botIk73Xq8nIuI9daird847eu+xoxHxj3WoKyI+2fdafTciXqhJXZdGxCMRcaT3/8m3VFFXwdou62XEUxHxaERsXPWTZWbt/9H97dbvA78NXAQ8CVy55JzNwNXAPwA316y2PwF+rXf7/cAXalLXq/pu7wD+uQ519c67GPgX4DGgU4e6gNuAv6vqvbWCurYCR4Df7B2/pg51LTn/L+j+/vLE66I7v/3+3u0rgWdq9N/yS8C7erffBHx+tc/XlJH7NcCJzDyZmb8A9gM39p+Qmc9k5lPA/9Wwtkcy82e9w8eA1X8al1vXT/sOXwlUsQAzsq6ejwOfAP63gppWUlfVitT1XmBvZj4PkJk/qkld/W4B/qkmdSXwqt7t3wBOVVBX0dquBL7Vu/3IgMcLa0q4zwDP9h3P9e6rg5XW9m7gG2OtqKtQXRHxgYj4Pt0gvaMOdUXENmBTZn6tgnoK19Xz9t5X5gcjYlNN6rocuDwivh0Rj0XE9prUBXSnGoAtwMM1qetjwDsjYg44SPdbRRWK1PYk8Pbe7bcBF0fEq1fzZE0J9xhwX13afArXFhHvBDrA/WOtqPd0A+47p67M3JuZvwP8FfDRsVc1oq6IuAD4JPDBCmrpV+T1+iqwOTOvBr4JfG7sVRWr60K6UzNvpDtCfiAi1tWgrgW7gAcz8+Ux1rOgSF23AJ/NzI3AW4DP995341aktg8Bb4iII8AbgHngpdU8WVPCfQ7oHyVtpLqvUqMUqi0irgM+AuzIzJ/Xpa4++4GdY62oa1RdFwOvAx6NiGeAPwIOVLCoOvL1yszn+v7bfRr4gzHXVKiu3jlfycwXM/MHwHG6YT/puhbsopopGShW17uBLwJk5r8Bv0r32i4Try0zT2XmTZm5jW5ekJk/WdWzVbGQUMJCxIXASbpf7RYWIn5/mXM/S7ULqiNrA7bRXUjZWrO6tvbd/jNgtg51LTn/UapZUC3yer227/bbgMdqUtd24HO92+vpfvV/9aTr6p13BfAMvT01NXm9vgHc1rv9e3QDduz1FaxtPXBB7/ZfA/es+vmqeMFLemHeAny3F5If6d13D92RMMAf0v1k/B/gOeBojWr7JvBfwBO9fwdqUtengKO9mh4ZFrJV1rXk3ErCveDrdW/v9Xqy93r9bk3qCuBvgWPA08CuOtTVO/4YcF8V9azg9boS+Hbvv+MTwJtrVNvNwPd65zwA/Mpqn8sdqpLUQk2Zc5ckrYDhLkktZLhLUgsZ7pLUQoa7JLWQ4S5JLWS4S1ILGe6S1EL/D28pvvcpsvzzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.arange(0.1,0.9,0.02), scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_opt = np.arange(0.1,0.9,0.02)[np.argmax(scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize per class threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpa_src.data.functional import apply_threshold, optim_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/modules/i12g/anaconda/3-5.0.1/envs/hpaic/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "thresholds = []\n",
    "for i in range(val_true.shape[1]):\n",
    "    thresholds.append(optim_threshold(val_true[:,i], val_preds[:,i], logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.stack([val_preds[:,i] > thresholds[i] for i in range(val_preds.shape[1])]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6205644298109639"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(val_true, tmp, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = TestDataset(DATA + 'raw/sample_submission.csv', transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test, batch_size=16, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    prediction = [model(img.to(device)) for img in test_dl]\n",
    "    prediction = torch.cat(prediction)\n",
    "#     prediction = preds2label(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = list(array2str(apply_threshold(prediction, thresholds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = np.arange(0.1,0.9,0.02)[np.argmax(scores)]\n",
    "# p = p_opt\n",
    "# # p = 0.3\n",
    "# preds = preds2label(prediction, threshold=np.log(p/(1-p)), fill_na=False)\n",
    "# preds = list(array2str(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = pd.read_csv(DATA + \"raw/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst.Predicted = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst.to_csv(DATA + \"processed/Submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008af0-bad0-11e8-b2b8-ac1f6b6435d0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000a892-bacf-11e8-b2b8-ac1f6b6435d0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0006faa6-bac7-11e8-b2b7-ac1f6b6435d0</td>\n",
       "      <td>0 25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0008baca-bad7-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000cce7e-bad4-11e8-b2b8-ac1f6b6435d0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id Predicted\n",
       "0  00008af0-bad0-11e8-b2b8-ac1f6b6435d0         2\n",
       "1  0000a892-bacf-11e8-b2b8-ac1f6b6435d0         5\n",
       "2  0006faa6-bac7-11e8-b2b7-ac1f6b6435d0      0 25\n",
       "3  0008baca-bad7-11e8-b2b9-ac1f6b6435d0         0\n",
       "4  000cce7e-bad4-11e8-b2b8-ac1f6b6435d0        25"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5000, 0.4900, 0.5100, 0.4200, 0.4400, 0.4500, 0.4000, 0.4500, 0.3800,\n",
       "        0.3900, 0.3900, 0.4200, 0.4200, 0.5600, 0.5900, 0.4400, 0.4000, 0.4300,\n",
       "        0.3600, 0.4100, 0.3100, 0.4200, 0.4800, 0.4400, 0.4300, 0.4300, 0.4100,\n",
       "        0.3700])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(torch.tensor(thresholds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_prob = torch.sigmoid(val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 15\n",
    "prec, rec, _ = precision_recall_curve(val_true[:,i], val_pred_prob[:,i])\n",
    "\n",
    "plt.plot(rec, prec)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model = train_model(pretrained, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import CategoricalAccuracy, Loss\n",
    "from ignite.handlers import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpa_src.models.metrics import F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = create_supervised_trainer(pretrained, optimizer_ft, criterion, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_function(engine):\n",
    "    val_loss = engine.state.metrics['loss']\n",
    "    return -val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1score = F1Score()\n",
    "handler = EarlyStopping(patience=5, score_function=score_function, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = create_supervised_evaluator(pretrained,\n",
    "                                        metrics={\n",
    "                                            'loss': Loss(criterion),\n",
    "                                            'f1': F1Score()\n",
    "                                        }, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.add_event_handler(Events.COMPLETED, handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(trainer):\n",
    "    evaluator.run(train_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Training Results - Epoch: {}  Avg loss: {:.2f} Avg f1: {:.2f}\"\n",
    "          .format(trainer.state.epoch, metrics['loss'], metrics['f1']))\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {}  Avg loss: {:.2f} Avg f1: {:.2f}\"\n",
    "          .format(trainer.state.epoch, metrics['loss'], metrics['f1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.run(train_loader, max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pretrained.state_dict(), DATA + '../models/torch_3epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 2.5641331955440414, 'f1': 0.24967516695377992}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.state.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hpaic]",
   "language": "python",
   "name": "conda-env-hpaic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
