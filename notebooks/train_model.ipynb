{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpa_src.config import get_data_dir, name_label_dict\n",
    "from hpa_src.data.datasets import readimg, HpaDataset, TestDataset#, train_val_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = get_data_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df = pd.read_csv(DATA + \"raw/png/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df['target_list'] = image_df['Target'].map(lambda x: [int(a) for a in x.split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "all_labels = np.array(list(itertools.chain(*image_df.target_list.values)))\n",
    "\n",
    "class_n = np.unique(all_labels, return_counts=True)[1]\n",
    "\n",
    "alpha = class_n / sum(class_n)\n",
    "\n",
    "image_df = image_df.drop(['target_list'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This code only run once\n",
    "# train_indx, val_indx = train_test_split(np.arange(image_df.shape[0]), test_size=0.2)\n",
    "\n",
    "# training = image_df.iloc[train_indx].reset_index(drop=True)\n",
    "# validation = image_df.iloc[val_indx].reset_index(drop=True)\n",
    "\n",
    "# training.to_csv(DATA+'raw/png/training.csv')\n",
    "# validation.to_csv(DATA+'raw/png/validation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = torch.from_numpy(alpha).float()\n",
    "\n",
    "# alpha = alpha.cuda()\n",
    "\n",
    "# alpha.cuda(alpha.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from hpa_src.data.transforms import ToPIL\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from hpa_src.models.loss import FocalLoss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_size = 299\n",
    "input_size = 512\n",
    "train_transform = transforms.Compose([\n",
    "    ToPIL(),\n",
    "    transforms.RandomResizedCrop(input_size, scale=(0.5,1)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(90),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.1149, 0.0922, 0.0553),\n",
    "#                          (0.1694, 0.1381, 0.1551))\n",
    "    transforms.Normalize((0.08069, 0.05258, 0.05487, 0.08282),\n",
    "                         (0.13704, 0.10145, 0.15313, 0.13814))\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    ToPIL(),\n",
    "#     transforms.Resize(input_size),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.1149, 0.0922, 0.0553),\n",
    "#                          (0.1694, 0.1381, 0.1551))\n",
    "    transforms.Normalize((0.08069, 0.05258, 0.05487, 0.08282),\n",
    "                         (0.13704, 0.10145, 0.15313, 0.13814))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    ToPIL(),\n",
    "#     transforms.Resize(input_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.05913, 0.0454 , 0.04066, 0.05928),\n",
    "                         (0.11734, 0.09503, 0.129 , 0.11528))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sampler, val_sampler = train_val_split(image_df.shape[0])\n",
    "# train_sampler, val_sampler = train_val_split(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HpaDataset(DATA + 'raw/png/training.csv', transform=train_transform)\n",
    "val_dataset = HpaDataset(DATA + 'raw/png/validation.csv', transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=16, #sampler=train_sampler,\n",
    "    num_workers=16\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=16, #sampler=val_sampler,\n",
    "    num_workers=16\n",
    ")\n",
    "\n",
    "dataloaders = {'train': train_loader, 'val': val_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pretrainedmodels\n",
    "# pretrained = pretrainedmodels.__dict__['inceptionresnetv2'](num_classes=1000, pretrained='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpa_src.models.inception import inceptionresnetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/modules/i12g/anaconda/3-5.0.1/envs/hpaic/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py:24: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 2 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    }
   ],
   "source": [
    "model = inceptionresnetv2(pretrained='imagenet')\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = BCEWithLogitsLoss()\n",
    "criterion = FocalLoss(gamma=2, logits=True)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-6)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_sizes = {'train': len(train_indx), 'val': len(val_indx)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = next(iter(dataloaders['train']))\n",
    "# pretrained(tmp[0].to_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from hpa_src.models.training import ModelTrainer\n",
    "from hpa_src.models.callbacks import TorchModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = ModelTrainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.compile(optimizer_ft, criterion, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checker = TorchModelCheckpoint('../models/torch_trained', monitor='val_f1', save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First train classifier layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in trainer.model.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in trainer.model.module.conv2d_last.parameters():\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(dataloaders['train'], dataloaders['val'], epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in trainer.model.parameters():\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(dataloaders['train'], dataloaders['val'], epochs=60, model_checker = checker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.subplot(121)\n",
    "fig = plt.figure(figsize=(13,5))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.plot(trainer.history.epoch, trainer.history.history['train_loss'], label='train_loss')\n",
    "ax1.plot(trainer.history.epoch, trainer.history.history['val_loss'], label='val_loss')\n",
    "ax1.legend()\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.plot(trainer.history.epoch, trainer.history.history['train_f1'], label='train_f1')\n",
    "ax2.plot(trainer.history.epoch, trainer.history.history['val_f1'], label='val_f1')\n",
    "ax2.legend()\n",
    "plt.savefig('lr0.0001_focal3channel.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validate threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resource\n",
    "rlimit = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (2048*2, rlimit[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"../models/torch_trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset = HpaDataset(DATA + 'raw/png/train.csv', transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loader = torch.utils.data.DataLoader(\n",
    "    all_dataset, batch_size=16, #sampler=val_sampler,\n",
    "    num_workers=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    val_preds = []\n",
    "    val_true = []\n",
    "    for inputs, labels in all_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        val_preds.append(model(inputs))\n",
    "        val_true.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = torch.cat(val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_true = torch.cat(val_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpa_src.data.functional import preds2label, preds2onehot, array2str\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for p in np.arange(0.1,0.9,0.02):\n",
    "    #tmp = preds2onehot(val_preds, threshold=np.log(p/(1-p)))\n",
    "    scores.append(f1_score(val_true, val_preds>np.log(p/(1-p)), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(0.1,0.9,0.02), scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_opt = np.arange(0.1,0.9,0.02)[np.argmax(scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize per class threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpa_src.data.functional import apply_threshold, optim_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = []\n",
    "for i in range(val_true.shape[1]):\n",
    "    thresholds.append(optim_threshold(val_true[:,i], val_preds[:,i], logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.stack([val_preds[:,i] > thresholds[i] for i in range(val_preds.shape[1])]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(val_true, tmp, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = TestDataset(DATA + 'raw/sample_submission.csv', transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test, batch_size=16, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    prediction = [model(img.to(device)) for img in test_dl]\n",
    "    prediction = torch.cat(prediction)\n",
    "#     prediction = preds2label(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = list(array2str(apply_threshold(prediction, thresholds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = np.arange(0.1,0.9,0.02)[np.argmax(scores)]\n",
    "# p = p_opt\n",
    "# # p = 0.3\n",
    "# preds = preds2label(prediction, threshold=np.log(p/(1-p)), fill_na=False)\n",
    "# preds = list(array2str(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = pd.read_csv(DATA + \"raw/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst.Predicted = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst.to_csv(DATA + \"processed/Submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sigmoid(torch.tensor(thresholds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_prob = torch.sigmoid(val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 25\n",
    "prec, rec, _ = precision_recall_curve(val_true[:,i], val_pred_prob[:,i])\n",
    "\n",
    "plt.plot(rec, prec)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model = train_model(pretrained, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import CategoricalAccuracy, Loss\n",
    "from ignite.handlers import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hpa_src.models.metrics import F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = create_supervised_trainer(pretrained, optimizer_ft, criterion, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_function(engine):\n",
    "    val_loss = engine.state.metrics['loss']\n",
    "    return -val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1score = F1Score()\n",
    "handler = EarlyStopping(patience=5, score_function=score_function, trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = create_supervised_evaluator(pretrained,\n",
    "                                        metrics={\n",
    "                                            'loss': Loss(criterion),\n",
    "                                            'f1': F1Score()\n",
    "                                        }, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.add_event_handler(Events.COMPLETED, handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(trainer):\n",
    "    evaluator.run(train_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Training Results - Epoch: {}  Avg loss: {:.2f} Avg f1: {:.2f}\"\n",
    "          .format(trainer.state.epoch, metrics['loss'], metrics['f1']))\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {}  Avg loss: {:.2f} Avg f1: {:.2f}\"\n",
    "          .format(trainer.state.epoch, metrics['loss'], metrics['f1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.run(train_loader, max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pretrained.state_dict(), DATA + '../models/torch_3epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 2.5641331955440414, 'f1': 0.24967516695377992}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.state.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hpaic]",
   "language": "python",
   "name": "conda-env-hpaic-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
